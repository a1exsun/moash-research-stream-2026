# MoELoRA

Source: Continual Learning of Large Language Models: A Comprehensive Survey

Core Mechanism:
MoE-based Parameter-Efficient Fine-Tuning for multi-modal Continual Learning. It introduces Mixture-of-Experts combined with LoRA for fine-tuning, achieving fine-grained task or cross-modal interference-free continual learning by processing various features.
