# FinPythia

Source: Continual Learning of Large Language Model

Core Mechanism:
Domain-specific Continual Pre-Training (CPT). It employs a carefully curated domain corpus for continual pre-training, enabling the model to achieve significant improvements in a target domain (e.g., finance) even with a very limited budget, while maintaining a high level of general knowledge. It emphasizes compliance, intellectual property, and data representativeness.
