# EverMemBench — 盛大陈天桥团队

**论文：** [arXiv 2602.01313](https://arxiv.org/pdf/2602.01313)
**来源：** 机器之心Pro Week 07
**类别：** Eval — LLM长期交互式记忆评估基准

---

## 问题

现有基准多聚焦二元、单主题对话，难以捕捉现实场景复杂性。

## 评估维度

- **细粒度回忆** — 具体事实的精准提取
- **记忆意识** — 识别历史信息与新场景的关联性并合理运用
- **用户画像理解** — 从长期对话中挖掘隐含习惯和特质

## 被评估系统

- 长上下文LLM：Gemini-3-Flash, GPT-4.1-mini, LLaMA-4-Scout等
- 记忆增强系统：Zep, Mem0, EverMemOS等

## 关键发现

- 多跳推理在多参与方场景急剧下降（最优Gemini-3-Flash仅26.51%），原因是相关信息分散在不同发言者、群组和时间点
- 时序推理是未解决难题（最优不足50%），模型难以处理信息的版本语义和演变逻辑
- 基于相似度的检索无法弥合查询与隐含相关记忆的语义鸿沟
- 记忆增强系统性能显著低于全上下文模型
