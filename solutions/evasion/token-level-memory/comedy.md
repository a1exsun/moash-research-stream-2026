# COMEDY — Chen et al. 2025

**论文：** Chen et al. (2025)
**来源：** arXiv 2512.13564v2 (Memory in the Age of AI Agents)
**类别：** Token-level Flat Memory — Unified Memory Generation, Compression & Reuse

---

## 问题

现有记忆系统通常需要多个独立模块分别处理记忆的生成、压缩和复用，流程复杂且各模块间协调成本高。

## 方法

单模型完成记忆的生成、压缩和复用三大核心操作，统一在一个端到端框架内。核心设计：
- **紧凑语义表示** — 生成紧凑的语义表示或query-response对，替代冗长的原始对话
- **分区语义摘要** — 按日/会话为单位进行分区，在每个分区内独立进行语义摘要，保持时序结构的同时实现压缩
- **单模型统一** — 同一个模型负责从原始对话生成记忆、对已有记忆进行压缩、以及在需要时复用已有记忆回答查询

## 特点

COMEDY的核心贡献在于证明了记忆管理的多个环节可以被统一到单一模型中，减少了多模块系统的工程复杂度和级联误差。

## 任务

- Summary
- Compression
- QA
