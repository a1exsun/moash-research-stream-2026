# Tutorial: Continual Learning of Large Language Model

来源: Continual Learning of Large Language Model

核心概念:
教程系统地分类了 LLM Continual Learning 的三大阶段:

1. Continual Pre-Training (CPT): 适应新领域、语言或更新知识。
2. Continual Instruction Tuning (CIT): 持续微调模型以适应新的任务指令或新工具。
3. Continual Alignment (CA): 持续处理模型的对齐税 (Alignment Tax)，并在不对齐历史知识造成灾难性遗忘的前提下调整安全性和人类偏好。

非参数化 CL 与 Lifelong Agents:
探讨了长短期记忆结构(如 HippoRAG, LightMem)及多智能体路由。
