# Survey: Continual Learning of Large Language Models

来源: Continual Learning of Large Language Models: A Comprehensive Survey

核心概念:
该综述文章首次从垂直连续性 (Vertical Continuity) 和水平连续性 (Horizontal Continuity) 两个维度划分 LLM 的 Continual Learning:

- Vertical Continuity: 包括从通用大规模预训练过渡到下游特定领域的 Domain-Adaptive Pre-Training (DAP) 以及相关的 CPT 和 CFT。
- Horizontal Continuity: 应对由于时间、内容和语言的持续变迁而引入的数据分布平移问题。

文中综合分析了 Parameter-Efficient Fine-Tuning、Replay、Architecture Routing 等策略。
