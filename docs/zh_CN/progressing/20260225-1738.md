# 2026-02-25: 解决 DSA 抗遗忘机制验证的算力瓶颈与演进思考

## 1. 初始背景与问题提出

基于 [Proposal 06](../proposal/proposal_06_dsa_continual_learning.md) 的核心洞察，我们意识到 DeepSeek V3 引入的 **动态稀疏注意力机制 (Dynamic Sparse Attention, DSA)** 在底层架构上天然映射了“压缩常识流”和“聚焦细粒度流”。这种类似大脑新皮层与海马体的非对称分离结构，如果在持续微调 (Continual Fine-Tuning) 中加以利用（仅更新聚焦流而冻结压缩流），有可能彻底终结大模型在学习新知识时遭遇的灾难性遗忘。

**面临困难**：DeepSeek V3/R1 等具备原生 DSA 结构的开源模型参数量高达数百亿甚至千亿级别（V3.2 也是如此），即便是仅仅对部分权重应用非对称微调，显存与算力开销也远远超出了绝大部分学术实验室的日常实验预算。

## 2. 第一次探索：微型开源 MoE 模型的误区

为了解决算力预算问题，初步设想是寻找 HuggingFace 上极其小巧的开源稀疏模型作为替代平替底座。由于“稀疏计算”概念的泛化，首先检索到的是诸如 `OLMoE-1B-7B` 或 `Qwen1.5-MoE-A2.7B` 等微缩版本的 Mixture of Experts 模型。

**盲点与纠正**：
很快我们意识到，上述开源社区主推的小参数“稀疏模型”**实际上实现的是前馈神经网络 (FFN / MLP) 层的稀疏路由 (Sparse FFN)**。而 Proposal 06 解决灾难性遗忘的突破口，是基于对大文本上下文 Query-Key 表征矩阵层面的解耦，也就是 **Attention 层本身的稀疏结构切割**。因此，使用普通的微缩 MoE 模型无法验证注意力拓扑隔离带来的收益。

截至目前，开源界并未发布过低至 1B～3B 参数级的、并且原生携带 DeepSeek DSA（Indexer + Top-K 选通注意力算法）权重的极小微缩版语言模型。这就逼迫我们在机制验证上寻找另辟蹊径的方法。

## 3. 第二次推演：降维与第一性机制论证

在学术顶会标准的实验场域中，如果要验证“某种物理隔离的注意力结构能防止遗忘”这一假说，并不一定需要挂载一套完美的、具备全知域常识的生产级大模型。我们转而构思出两种极低算力成本的验证分支：

### 路线 A：后天手术魔改流 (Surgery on Dense Sub-1.5B Models)

既然无法直接获取微型原生 DSA，不如挟持一个成熟的开源稠密小模型（如 `Qwen2.5-1.5B` 或 `Llama-3.2-1B`），强行在其 Pytorch 前向传播层对 Attention Heads 执行 1:1 分割改写。

- **压缩流模拟**：直接在反向传播图中 `requires_grad=False` 彻底冻结前一半 Attention 及其下挂 MLP，让其化作静态常识词典；
- **稀疏聚焦流模拟**：在后一半 Attention 强制套用 Top-K Masking（强迫其注意力变为硬稀疏通路），并且放开甚至放大这些参数更新率。
- **预期**：通过这个极具性价比的代码级外科手术，既保留了基座底盘卓越的自然语言常识网络，又强行建立了一个类似 DSA 的免疫隔离网，以测试这种“后天形成的注意力非对称微调”能否抵抗 TRPG 长程对话设定的遗忘。

_(该路线已被具体化并提取为：[Proposal 07](../proposal/proposal_07_dsa_attention_surgery.md))_

### 路线 B：微型原生沙盒流 (Tiny-DSA Sandbox Pre-training)

考虑到顶会 Reviewer 可能会认为“强行外科手术切开稠密大模型的注意力网络，会导致原有的预训练微结构知识严重走样失效”。那么，最为“纯洁”与具有说服力的做法，就是回归极度简单的参数规模（~100M 也就是约 0.1B）。

- **结构**：直接抽离借用 DeepSeek 开源仓库中纯粹的 DSA Indexer 与 Top-K 算子计算单元，拼装一个仅仅包含 4~8 层的微型骨干。
- **温床**：在极其微小的极简合成语言数据集（如 `TinyStories` 单卡一两天便能结束收敛）上从零开始预训练一个小号的、懂得基本婴幼儿常识故事的基准底座。并以此为起跑线，在微调实验集上，和具有相同尺寸的传统 Dense Transformer 打对台，看谁能在“一百次剧本颠覆”的洗礼后还能保持讲故事的逻辑性。

_(该路线已被具体化并提取为：[Proposal 08](../proposal/proposal_08_dsa_tiny_sandbox.md))_

## 4. 结论与下一步

这套思维推演解决了**“如何以极低硬件花销去验证一项需要庞大原生理工科底座才特有的架构创新”**的核心矛盾，将宏大的持续学习瓶颈从“算力霸权问题”降阶成了单人 4090 极客可以触碰的“架构数学分离”实验。这为后续我们的学术验证确立了坚实的实操可能。
