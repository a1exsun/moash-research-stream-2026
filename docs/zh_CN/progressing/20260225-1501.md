# 2026-02-25 探讨：规模 (Scale)、隐式稀疏性 (Implicit Sparsity) 与 Dense Transformer 的持续学习潜力

## 核心探讨问题

随着模型参数量 (Scale) 的极速增长，Dense Transformer 在持续学习中表现出“越来越强”的抗遗忘能力。这引出一个核心的本体论问题：
**有没有可能，Dense Transformer 仅凭 Scale 和恰当的机制设计，就能真正解决持续学习问题，并成为一套强大的系统（而不是走向 dead-end）？**

## 第一性原理分析：从"死局"到"金矿"的认知翻转

### 1. 为什么 Scale “看起来”在解决问题？（高维几何与过参数化视角）

在经验上，我们观察到诸如 LLaMA-3 (70B) 在进行持续微调时，比 GPT-2 (124M) 的遗忘要少得多。其底层的几何原因包括：

- **正交性红利（Curse of Dimensionality 的反面）**：在高维空间 $\mathbb{R}^d$ 中，两个随机向量内积的期望约等于 $1/\sqrt{d}$。参数量足够大时，不同任务的梯度更新方向大概率是**近乎正交**的，在任务 B 上走一步，在任务 A 的 loss 表面上几乎没有投影（不影响旧知识）。
- **过参数化带来的冗余流形 (Flat Minima)**：全局最小解不是一个点，而是一个巨大的连通流形。学习新任务时，模型可以沿着旧任务的“平坦盆地”滑动，找到兼顾新旧任务的解，因为连通体积极大概率非空。

### 2. Dense 架构的根本阿喀琉斯之踵

尽管高维正交性能极大延缓遗忘，但如果系统是真正的“Dense”（每次传播更新 100% 神经元），依然无法摆脱物理法则的严酷约束：

- **特征叠加 (Superposition) 的必然代价**：只要特征数大于神经元数，模型就会被迫把多个特征压缩到同一组神经元上。在 Dense 模型中，学习新知识必然意味着**强行修改叠加字典**。即使单次干预极小，但每次更新都在做**全局涂抹**，长此以往必然导致灾难性崩溃。
- **可塑性丧失 (Loss of Plasticity)**：这是比遗忘更可怕的幽灵。Dense 网络在长序列持续训练中，会出现死神经元 (Dead Neurons) 或特征坍缩 (Rank Collapse)。网络的表征能力逐渐退化，**导致就算不遗忘旧知识，也再也学不进新知识了**。原因是反复的全局 Dense 更新破坏了初始化时的良性几何结构，让 Loss Landscape 变得病态。

### 3. 破局点：大模型其实是“隐式稀疏的” (Implicitly Sparse)

我们心智上必须扭转一点：经验上的“Dense Transformer”在数学意义上并不是真正的“稠密”。

- **激活函数的天然截断**：通过 ReLU/SwiGLU/GeLU 等激活函数，前向传播中真正激活的神经元比例（Activation Sparsity）往往低于 5% 甚至 1%。
- **Scale 放大的是“涌现出的隐式稀疏路由”**：在这个视角下，参数越多的模型内部有越多的“空闲休眠区”。前馈网络 (FFN) 退化成了极其庞大的 Key-Value 记忆网络，特定概念其实只激活极少数特定路径。
  **结论**：Scale 之所以有效，恰恰是因为它自发涌现出了极端的 Activation Sparsity (极小的 $s$ / $a$)。

### 4. 为什么不加干预的 Dense SFT 还是会崩？（痛点定标）

既然大模型有无数“空房间”，为什么标准顺序微调（SFT）还会发生灾难性遗忘？

- **SGD/Adam 是“懒惰且贪婪”的**：当新数据进来时，梯度流必然寻找 loss 下降最快的捷径。而这条捷径，往往是**修改那些已经被预训练高度激活、具备大权重的“核心枢纽 (Hub Neurons)”**，因为它们掌握着通用的泛化特征。
- **结果**：即使模型中有 95% 的休眠网络，标准优化算法也不会主动去唤醒它们。它反而会反复修改那 5% 被所有任务共享的权重。**隐式稀疏性如果不加机制干预，只是一种无法利用的静态资源，反而会因为 SGD 的路径依赖导致严重的 Write Interference。**

## 对 Proposal 集的重新定位与学术升华

在“大模型蕴含海量隐式稀疏空间，只是缺乏合理引导”的前提下，本组 Proposal 的学术立意从“经验刷分”直接升维为“**提取、保护和分配隐式稀疏性的手术刀**”：

- **重构的 Proposal 01 (Selective Write / 选择性写入)**：现在它是用来对抗 SGD 懒惰的抗体。通过引入门控机制，我们**强行抑制旧任务的高激活区域（保护已有知识），重定向梯度流去唤醒那些巨大的“空闲房间”**。这是利用既有 Dense 参数空间做 CL 的正统策略。
- **重构的 Proposal 02 (Dense -> Sparse 转换)**：不再是单纯的模型压缩。由于大内存里有大量隐式休眠神经元，转换为结构化稀疏（如 2:4）**本质上是“强制显式化” (Manifestation)**。它用物理栅栏把隐式稀疏性固定死，强迫后续学习在分离好的轨道里跑，彻底杜绝 SGD 的“全局涂抹”。
- **重构的 Proposal 04 (CDCL 曲率分解)**：在 Dense 模型的庞大参数中寻找“空房间”，等价于寻找 Fisher 矩阵的零空间（Null Space）或平坦方向。CDCL 就是一套数学工具，用来在 Dense 空间里精确映射这些“隐式空闲子空间”，并只允许参数在其中移动。
- **重构的 Proposal 05 (容量天花板)**：它作为终极物理约束存在。告诉你即使完美开发利用了隐式稀疏性，单机制 (Single-regime) 系统依然有 $C \cdot B$ 的极限上界。但这反而突出了在我们触及那个遥远的天花板之前，发掘和 allocate 现存的隐式稀疏性是当下极具价值的金矿路线。

## 结论叙事 (Narrative) 总结

如果你要在顶会打出这套拳法，核心叙事应该是：

> “长期以来，研究者认为在保持模型 Dense 架构的同时实现可持续学习是难以逾越的障碍，倾向于引入外部记忆或 MoE。反之，我们认为得益于 Scale，现代大模型内部蕴藏着极高的隐式稀疏维度。持续学习的灾难性遗忘与可塑性丧失，并非由于绝对容量不足，而是由于标准优化算法（SGD）具有贪婪的路径依赖，无法在参数空间中合理分配（Allocate）和保护这些隐式稀疏空间。
>
> 我们的研究方向，就是在不改变预训练 Dense 架构整体分布的前提下，通过 [选择性写入梯度路由 / 子空间约束 / 后验结构化稀疏] 等机制，引导梯度流安全入驻这些隐式的空闲流形。从而在现有架构上，释放被低效优化算法所掩盖的庞大持续学习潜力。”
