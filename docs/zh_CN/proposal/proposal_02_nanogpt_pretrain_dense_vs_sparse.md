# Proposal 02: 基于 nanochat 的持续学习 Cross-over 效应

## 核心洞察

传统的持续学习研究执着于试图延缓灾难性遗忘，让模型成为不遗忘任何旧知识的"全知全能"者。但根据人脑学习的启发，人类在成长过程中也会遗忘大量早期或无用的事实知识，最终收敛为一个**领域专家**（同时保留基础的逻辑与通用语言能力）。

在这里我们提出核心的 **Cross-over 假设**：**持续学习模型最初的能力不如基线模型，但是在多轮微调后，其能力将不仅超过基线模型，还会突破基线模型的微调极限。**

因此，本实验的核心主张是：为了实现真正的持续学习架构，我们可能需要牺牲一部分 Transformer 架构（Dense）天然的强大信息压缩与初始泛化能力（即接受最初能力的劣势）。只要这种新型的持续学习架构（例如原生稀疏架构）能够在多轮目标领域微调后，彻底打破传统 Dense 模型在微调中遭遇的天花板并实现上穿跨越，那么这种架构上针对"初始容量"的牺牲就是具备巨大价值的。

## 假设

### H1 (初始能力差异)

在相同的预训练算力与数据下，传统的 Dense Transformer 由于其全局注意力和密集的反向传播，会展现出比"具备独立隔离机制的新型持续学习架构（如原生稀疏）"更强的初始通识能力和更低的 Perplexity。

### H2 (Cross-over 交叉效应)

在进入特定目标领域的多轮持续微调后：

- **基线模型 (Dense)**：受限于物理层面的权重交叉继承，很快会遭遇领域知识吸收的瓶颈。在强行洗掉旧有特征的过程中，其目标领域的性能会很快触碰天花板（**微调极限**），难以进一步提升，甚至因为过度微调导致通用能力崩溃。
- **持续学习架构模型 (Sparse 等)**：正如 Cross-over 假设所述，该模型**最初的能力不如基线模型**（起点较低）。但得益于其架构对灾难性遗忘的相互覆写防御，它具备远大于 Dense 模型的持续学习容量。最终在多轮微调序列的某个节点，其不仅能够稳定超越同步微调的基线模型，最终的表现更是会**超过基线模型本身的微调极限**，形成明确的 Cross-over 能力交叉曲线。

## 方案

### 基础配置

- **基座规模**：nanochat (约 561M 参数，depth=20 官方推荐配置)，以保证验证此类底层预训练假设的高效可行性。
- **评测分离体系**：
  - **通用智能底线集 (General Intelligence Baseline)**：仅测试最基础的语言流利度、基础逻辑推断（允许遗忘具体百科事实知识，但不允许丧失底层的"思考流利度"）。
  - **目标深水区领域集 (Target Domain)**：例如深度的医疗长文本、复杂的代码库或特定企业的私有知识域。

### Phase A: 预训练阶段

分别使用相同的通用语料（如 FineWeb-Edu 的一个子集）从头预训练两个架构：

1. `Model-Dense`：标准结构 nanochat。
2. `Model-CL`：带有持续学习特殊机制的 nanochat（如引入 Proposal 01 中的结构化稀疏设计来限制交叉继承）。
   _设定检查点：验证在通识测试集上，`Model-Dense` 的表现确有初始压制优势。_

### Phase B: 持续域演化阶段

将两个预训练好的模型同时投入目标领域（Domain X）进行无尽的流式长序列微调。

- 每注入一定数据量（例如每 10M Tokens）作为一个 Epoch 节点，同时抓取两个模型进行 Domain X 专业测试与通用底线集测试。
- 绘制两条随训练时间/数据量推移的能力演进对比曲线。

## 算力成本评估

利用 nanochat 的中小规模（561M），跑通这套包含"预训练 + 无尽微调"的全链路端到端实验，整体算力被限制在可控范围内（单卡 A100 约一周、8×H100 集群数天内即可跑完 Phase A+B）。这使得我们可以跳出在庞大 SOTA 模型上只能做"表面修补"的困境，直接且彻底地回答"底层架构重置是否有意义"这一根本性问题。

## 预期产出

### 核心观察点 - 领域的 Cross-over 曲线

构建 X 轴为"多轮持续微调的 Token 注入量"，Y 轴为"Domain X 表现"的折线图。我们期待观察到符合 Cross-over 假设的现象：在图表左侧（起始阶段），`Model-CL` 表现低于 `Model-Dense`；而在 X 轴的右侧深水层（多轮微调末端），`Model-CL` 成功上穿跨越 `Model-Dense` 的曲线，并且最终的性能峰值显著**超过 `Model-Dense` 所能达到的最高微调极限**。

### 辅助观察点 - 通用底线维持

在通用智能底线测试集上，观察两者遗忘速率的差异，证明 `Model-CL` 是"健康地遗忘非必要事实"，而不是像 Dense 那样最终陷入"灾难性的底层语言架构崩塌"。
