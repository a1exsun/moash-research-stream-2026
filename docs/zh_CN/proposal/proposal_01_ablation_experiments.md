# Proposal 01: 持续学习机制消融实验

## 目标

在统一训练预算下，定量分离以下机制对灾难性遗忘的独立贡献与交互贡献：

1. 结构化稀疏拓扑（Topology）
2. 选择性写入门控（Selective Write）
3. 离线巩固/回放（Sleep Replay）

核心问题：
- 哪个机制贡献最大？
- 哪些机制是可叠加的？
- 哪些机制存在边际收益递减？

---

## 假设

### H1
仅引入结构化稀疏拓扑即可显著降低遗忘，但不足以单独达到长期稳定。

### H2
选择性写入在相同算力下能提升“学习速度-保持率”的联合效率。

### H3
离线巩固对长期序列稳定性最关键，但与拓扑/门控组合时收益高于单独使用。

---

## 实验设计

## 1. 基础配置

- Backbone：固定同一模型规模（建议 1B-3B 或可复现小规模基座）
- 数据：固定域序列（代码 -> 数学 -> 医疗 -> 法律 -> 对话）
- 训练：相同 token、step、optimizer、batch

## 2. 消融组（2x2x2）

以三机制开关构建 8 组：

- `T0 W0 R0`：Dense 基线
- `T1 W0 R0`：仅拓扑稀疏
- `T0 W1 R0`：仅选择性写入
- `T0 W0 R1`：仅离线巩固
- `T1 W1 R0`
- `T1 W0 R1`
- `T0 W1 R1`
- `T1 W1 R1`

其中：
- `T1`：固定结构化稀疏（2:4 或 block）
- `W1`：按 surprise/uncertainty 触发写入
- `R1`：固定频率 replay（真实缓存或生成缓存，单一方案先固定）

## 3. 公平性约束

- 报告 `same-shape` 与 `matched-FLOPs` 两套结果
- 每组至少 3 seeds
- 预注册主指标与统计检验方式

---

## 指标体系

主指标：
1. Average Forgetting
2. BWT
3. Retention@k（每阶段旧域保持）

次指标：
1. FWT
2. 新域收敛速度
3. 单位 FLOPs 收益

稳定性指标：
1. 域顺序扰动方差
2. seed 方差

---

## 预期输出

1. 机制贡献分解图（主效应 + 交互效应）
2. 每机制的边际收益曲线
3. 可执行结论：
- 必须保留的最小机制集合
- 可暂时删除的低收益复杂度

---

## 风险与应对

### 风险1：实验组合过多，成本过高
应对：先跑 4 组主效应（`T/W/R` 单开 + baseline），再补交互组。

### 风险2：离线巩固方案引入额外混淆
应对：R1 先固定为单一 replay 配方，不在本 proposal 内比较 replay 变体。

### 风险3：结论依赖特定域顺序
应对：至少 2 种域顺序重跑关键组。

---

## 里程碑

1. Week 1-2：框架与四组主效应
2. Week 3-4：完整 8 组 + 统计分析
3. Week 5：机制取舍结论与下一 proposal 输入

