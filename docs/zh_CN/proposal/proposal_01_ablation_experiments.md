# Proposal 01: 持续学习机制消融实验

## 目标

在统一训练预算下，定量分离以下机制对灾难性遗忘的独立贡献与交互贡献：

1. 结构化稀疏拓扑（Topology）
2. 选择性写入门控（Selective Write）
3. 离线巩固/回放（Sleep Replay）

核心问题：

- 哪个机制贡献最大？
- 哪些机制是可叠加的？
- 哪些机制存在边际收益递减？

---

## 假设

### H1

仅引入结构化稀疏拓扑即可显著降低遗忘，但不足以单独达到长期稳定。

### H2

选择性写入在相同算力下能提升“学习速度-保持率”的联合效率。

### H3

离线巩固对长期序列稳定性最关键，但与拓扑/门控组合时收益高于单独使用。

---

## 实验设计

## 1. 基础配置

- Backbone：固定同一模型规模（使用 nanoGPT 规模，即 GPT-2 Small 约 124M 参数量）
- 数据：固定域序列（代码 -> 数学 -> 医疗 -> 法律 -> 对话）
- 训练：相同 token、step、optimizer、batch

## 2. 消融组（2x2x2）

以三机制开关构建 8 组：

- `T0 W0 R0`：Dense 基线
- `T1 W0 R0`：仅拓扑稀疏
- `T0 W1 R0`：仅选择性写入
- `T0 W0 R1`：仅离线巩固
- `T1 W1 R0`
- `T1 W0 R1`
- `T0 W1 R1`
- `T1 W1 R1`

其中：

- `T1`：固定结构化稀疏（2:4 或 block）
- `W1`：按 surprise/uncertainty 触发写入
- `R1`：固定频率 replay（真实缓存或生成缓存，单一方案先固定）

## 3. 公平性约束

- 报告 `same-shape` 与 `matched-FLOPs` 两套结果
- 每组至少 3 seeds
- 预注册主指标与统计检验方式

---

## 指标体系

主指标：

1. Average Forgetting
2. BWT
3. Retention@k（每阶段旧域保持）

次指标：

1. FWT
2. 新域收敛速度
3. 单位 FLOPs 收益

稳定性指标：

1. 域顺序扰动方差
2. seed 方差

---

## 预期输出

1. 机制贡献分解图（主效应 + 交互效应）
2. 每机制的边际收益曲线
3. 可执行结论：

- 必须保留的最小机制集合
- 可暂时删除的低收益复杂度

---

## 算力成本评估 (nanoGPT 规模)

针对基于 nanoGPT (GPT-2 Small, 124M) 规模的持续学习实验算力成本估算：

**基本假设与计算依据：**

- **模型参数量**：124M (1.24亿) 参数。
- **训练数据量**：由于模型较小，容易过拟合及快速收敛，总序列共 5 个域，假设每轮训练数据总量控制在 1B Tokens（10亿）。
- **FLOPs 理论值**：`6 * 124M * 1B = 7.44e17 FLOPs`。
- **硬件效率**：单张 Nvidia A100 (80GB) 的有效算力保守按 150 TFLOPs（`1.5e14 FLOPs/s`）计算。另外也可以在消费级显卡（如 RTX 4090）或更低端 GPU 上轻松运行。

**单次实验（单组 1 个 Seed）训练成本：**

- **单轮耗时**：`7.44e17 / 1.5e14 = 4960 秒` ≈ **1.4 小时 (单张 A100)**。如果在 RTX 4090 或 V100 上，通常单轮也在 2-3 小时内可完成。

**完整实验（2x2x2=8 组）与多 Seed 总开销估算：**

- **总训练轮数**：8 组消融实验 × 3 个不同随机种子 = **24 轮独立实验**。
- **计算总预算**：`24 × 1.4 = 33.6 A100 GPU 小时`。
- **资金与时间成本**：
  - 若租用云端 A100（按 $2/小时），**总成本不到 $70 USD**。
  - 使用单卡 A100，**仅需 1.5 天** 即可跑完所有 8x3=24 组实验。使用单台 8 卡 A100 仅需数小时。
  - 即使使用单张消费级显卡（如自带的 RTX 4090），跑完全部实验大概只需 3-4 天的时间。

**算力优势：**
转换为 nanoGPT 规模后，算力成本从数万美元和数十天直接断崖式下降至百元以内和两三天。这允许我们拥有极高的实验迭代速度：在一天内得到（2x2x2）机制交互效应的雏形反馈，从而快速验证假设。

---

## 风险与应对

### 风险1：小模型结论在规模缩小后失效 (Scale Misalignment)

应对：学术界有研究表明，100M 以上的网络足以展示神经网络在灾难性遗忘上的本质特征。若结果突破预期，可考虑选拔部分高收益机制组合上升至 1.5B 做最终复现验证。

### 风险2：离线巩固方案引入额外混淆

应对：R1 先固定为单一 replay 配方，不在本 proposal 内比较 replay 变体。

### 风险3：结论依赖特定域顺序

应对：至少 2 种域顺序重跑关键组。

---

## 里程碑

1. Week 1-2：框架与四组主效应
2. Week 3-4：完整 8 组 + 统计分析
3. Week 5：机制取舍结论与下一 proposal 输入
