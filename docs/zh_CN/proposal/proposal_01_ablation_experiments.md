# Proposal 01: 持续学习机制消融实验

## 核心洞察

在统一模型规模、基线能力的前提下，定量分离以下两种基于背景洞察的核心机制对灾难性遗忘的独立贡献与交互贡献：

1. **结构化稀疏架构 (Sparse Topology)**：旨在打破 Dense 特性，限制权重的交叉继承。
2. **经验重放 (Experience Replay)**：旨在模拟睡眠时短期记忆向新皮层的重放过程。

对应两个核心问题：

- 定量分析两种机制对持续学习的影响。
- 这两种机制叠加时，是否具备显著的正向协同效应？

## 假设

### H1 (稀疏架构的作用)

将 Dense 架构替换为稀疏架构，可以通过参数隔离缓解权重的交叉继承，从而显著降低微调时的旧知识覆写。

### H2 (经验重放的作用)

通过混合历史数据进行经验重放，能够有效巩固网络中的旧知识，提升持续学习的综合保持率。

### H3 (交互效应)

稀疏架构与经验重放机制存在互补性。稀疏架构减少了物理冲突，而经验重放巩固了特征表示，两者结合后的遗忘缓解效果将高于各自单独起效的叠加。

## 方案

### 基础配置

- **Backbone**：固定同一模型规模（使用 nanoGPT 规模，即 GPT-2 Small 约 124M 参数量）
- **数据**：固定多域序列任务（例如：代码 -> 数学 -> 医疗 -> 法律 -> 对话）
- **训练**：相同 token 量、step、optimizer 和 batch size 等超参数体系

### 消融组（2x2）

以双机制开关构建 4 组消融：

- `T0 R0`：Dense 基线（无稀疏，无重放）
- `T1 R0`：仅稀疏架构（如 MoE 或 2:4 block 稀疏，无重放）
- `T0 R1`：仅经验重放（Dense 架构，加入混合数据重放机制）
- `T1 R1`：稀疏架构 + 经验重放

其中：

- `T` = 架构机制 (Topology)
- `R` = 重放机制 (Replay)

**公平性原则：** 报告 matched-FLOPs 与 same-shape 两套维度的结果对比，每组实验执行 ≥3 个随机种子 (seeds) 以消除方差。

## 算力成本评估

针对基于 nanoGPT (124M) 规模的实验算力耗费估算：

### 基本假设与计算依据

- **模型参数量**：124M 参数。
- **训练数据量**：由于模型较小，序列中 5 个域的总训练数据量控制在 1B Tokens（10亿）。
- **理论计算量**：`6 * 124M * 1B = 7.44e17 FLOPs`。
- **硬件效率**：单张 Nvidia A100 (80GB) 的有效算力按保守的 150 TFLOPs（`1.5e14 FLOPs/s`）计算。

### 单次实验单组耗时

- **单轮耗时**：`7.44e17 / 1.5e14 = 4960 秒` ≈ **1.4 小时 (单张 A100)**。如果使用单张消费级显卡（如 RTX 4090）也通常在 3-5 小时内。

### 完整实验总开销

- **总训练轮数**：4 组消融实验 × 3 个不同随机种子 = **12 轮独立实验**。
- **计算总时长**：`12 × 1.4 = 16.8 A100 GPU 小时`。
- **资金与时间成本**：
  - 租用云端 A100 ($2/h) 成本仅需约 **$35 USD**。
  - 使用单卡 A100，**仅需约 1 天** 即可跑完所有 12 组实验。使用消费级单卡（RTX 4090）也仅需 3 天左右。
  - 考虑额外的摩擦成本，总计 2 周内可完成。

降维到 nanoGPT 规模进行系统消融实验，能以极其微小的代价快速提供清晰的物理层与机制层面的定量结论。

## 预期产出

1. 机制定量贡献图（主效应分析与交互效应分析）。
2. 在 nanoGPT 规模上的明确实证结论验证假设，并为 scaling 到 SOTA 大模型的表现提供依据支持。
