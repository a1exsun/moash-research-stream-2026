# Proposal 01: 持续学习机制消融实验

## 研究动机

从已有文献来看，缓解灾难性遗忘的策略可以大致归为两类。我想尝试在统一模型规模和基线能力的前提下，定量分离它们各自的贡献与可能的交互效应：

1. **结构化稀疏架构 (Sparse Topology)**：一种假说认为，稀疏连接可能有助于减少参数间的交叉干扰。
2. **经验重放 (Experience Replay)**：被认为与大脑睡眠期记忆巩固过程存在一定类比关系，通过混合历史数据来维持旧知识。

想探索的两个问题：

- 这两种机制分别对持续学习有多大影响？
- 两者叠加时，是否可能存在正向协同效应？

## 假设

### H1 (稀疏架构的作用)

如果将 Dense 架构替换为稀疏架构，参数隔离可能有助于缓解权重的交叉干扰，从而降低微调时旧知识被覆写的程度。

### H2 (经验重放的作用)

通过混合历史数据进行经验重放，可能有助于巩固网络中的旧知识，提升持续学习的综合保持率。

### H3 (交互效应)

如果稀疏架构与经验重放机制存在互补性——稀疏架构减少物理冲突，经验重放巩固特征表示——那么两者结合后的遗忘缓解效果可能高于各自单独贡献的简单叠加。

## 方案

### 基础配置

- **Backbone**：使用 nanochat 官方推荐权重规模（depth=20，约 561M 参数）
  - 20 层 Transformer，模型维度 1280，10 个注意力头（每头 128 维）
  - 词表大小 65,536（2^16），上下文长度 2,048
  - 精度 BFloat16，优化器 Muon（矩阵参数）+ AdamW（Embedding 参数）
- **数据**：固定多域序列任务（例如：代码 -> 数学 -> 医疗 -> 法律 -> 对话）
- **训练**：相同 token 量、step、optimizer 和 batch size 等超参数体系

### 消融组（2x2）

以双机制开关构建 4 组消融：

- `T0 R0`：Dense 基线（无稀疏，无重放）
- `T1 R0`：仅稀疏架构（如 MoE 或 2:4 block 稀疏，无重放）
- `T0 R1`：仅经验重放（Dense 架构，加入混合数据重放机制）
- `T1 R1`：稀疏架构 + 经验重放

其中：

- `T` = 架构机制 (Topology)
- `R` = 重放机制 (Replay)

**公平性原则：** 报告 matched-FLOPs 与 same-shape 两套维度的结果对比，每组实验执行 ≥3 个随机种子 (seeds) 以消除方差。

## 算力成本评估

针对基于 nanochat (561M) 规模的实验算力耗费估算：

### 基本假设与计算依据

- **模型参数量**：561M 参数（nanochat depth=20 官方推荐配置）。
- **训练数据量**：5 个域的总训练数据量控制在 5B Tokens（50亿），每个域约 1B Tokens。
- **理论计算量**：`6 × 561M × 5B = 1.68e19 FLOPs`。
- **硬件效率**：单张 Nvidia A100 (80GB) 的有效算力按保守的 150 TFLOPs（`1.5e14 FLOPs/s`）计算。

### 单次实验单组耗时

- **单轮耗时**：`1.68e19 / 1.5e14 ≈ 112,000 秒` ≈ **31 小时 (单张 A100)**。
- 如使用 8×H100 集群（nanochat 官方推荐配置），单次训练可压缩至约 **4-5 小时**。

### 完整实验总开销

- **总训练轮数**：4 组消融实验 × 3 个不同随机种子 = **12 轮独立实验**。
- **计算总时长**：`12 × 31 ≈ 373 A100 GPU 小时`。
- **资金与时间成本**：
  - 租用云端 A100 ($2/h) 成本约 **$750 USD**。
  - 若使用 8×H100 节点 ($24/h)，`12 × 5h = 60 节点小时`，成本约 **$1,440 USD**，但仅需 **约 3 天** 即可完成全部实验。
  - 使用单卡 A100 串行执行，约需 **16 天**。
  - 考虑额外的调试与摩擦成本，总计 3-4 周内可完成。

## 预期产出

1. 机制定量贡献图（主效应分析与交互效应分析）。
2. 在 nanochat 561M 规模上获得初步实证数据，为后续是否值得 scaling 到更大规模提供参考。
