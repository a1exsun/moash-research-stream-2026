# Literature Notes

文献批判性阅读笔记。每篇论文记录：核心贡献、方法、隐含假设、实验设计的混淆变量、与本研究的关系。

---

## 待整理

以下文献已在 `refs/` 中，待深入阅读并记录笔记：

- [ ] **arXiv-2512.13564v2** — Agent Memory survey，关注 Sec 3 (Parametric Memory) 部分
- [ ] **Continual Learning of Large Language Model** — CL综述
- [ ] **Continual Learning of Large Language Models: A Comprehensive Survey** — CL综述
- [ ] **机器之心Pro Week 07** — LLM记忆问题专题

## 已在proposal中引用但未深入阅读的关键论文

- [ ] CHT (2025) — Brain-inspired sparse training, 1%-5%密度匹配全连接
- [ ] Dual Lottery Ticket (2025) — Expander graph mask + EWC做CL，最接近本研究但未分离稀疏性独立贡献
- [ ] Jessy Lin et al. (2025) — Sparse Memory Finetuning，稀疏更新（非拓扑稀疏）
- [ ] O-LoRA (Wang et al. 2023) — 正交子空间学习，容量瓶颈问题
- [ ] RigL (2020) — 动态稀疏训练
- [ ] EWC (2017) — Elastic Weight Consolidation
- [ ] Masse et al. (2018, PNAS) — 激活稀疏性 + 上下文门控

---

## 笔记模板

```markdown
### [论文标题] (作者, 年份)
**来源：** arXiv/会议
**核心贡献：**
**方法：**
**隐含假设：**
**实验设计问题/混淆变量：**
**与本研究的关系：**
**批判性评价：**
```
