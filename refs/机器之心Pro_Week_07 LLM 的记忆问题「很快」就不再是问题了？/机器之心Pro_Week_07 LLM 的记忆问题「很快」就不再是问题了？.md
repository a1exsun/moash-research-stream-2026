# Week 07 · LLM 的记忆问题「很快」就不再是问题 了？

2026.02.15


### ① LLM 的记忆问题「很快」就不再是问题了？


引言：当前，智能体正经历范式转变，从高效的单任务执行模式，逐步向动


态环境下的持续自适应、能力演化与经验积累模式转型。在此背景下，AI


Memory 作为核心基石，赋能智能体保持行为一致性、做出理性决策并实现


高效协作。在长期探索中，AI Memory 已经分化为「Agent Memory」与


「LLM Memory」两条截然不同的演进路径。


OpenClaw 的「长效记忆」为何不代表「 AI 拥有持久记忆」？


1. 开源项目 OpenClaw（原名 Clawdbot 及 Moltbot）在 2026 年初引起


了一阵病毒式流行。在相关讨论中，在相关讨论中，OpenClaw 的核心


竞争力在于它被视为「有手的 Claude」，能够跨越数周乃至数月的会


话维持持久性记忆，通过学习用户的偏好、语气及特定工作流，使 AI


从「对话窗口」转变为真正「懂你」的数字雇员。


① 自 2025 年底发布以来，OpenClaw 项目在 GitHub 上的热度极速


攀升，在 2026 年 2 月已突破 19 万颗星。[1-1]


2. 在此热度下，AI 社区对 OpenClaw 项目热议的核心不仅在于能够执


行复杂的跨平台操作，更在于其展示出的「长效记忆」能力是否代表


「AI 拥有持久记忆」的未来是否即将来临。


① 伴随 LLM 及 Agent 应用的突破和广泛应用，AI 的记忆


（Memory）问题被视为推动更高阶智能演进的核心瓶颈，围绕改善


AI 记忆力的研究已成为 LLM 相关研究中最受关注的前沿方向之一。


② 在 2025 年先后涌现了诸多有关改善 AI Memory 的探索，如


Meta 团队的「SMF」工作、谷歌提出的「Nested Learning」范式及


HOPE 模型、MIT 的「BEYOND CONTEXT LIMITS」工作等（详见


Pro 会员通讯 2025 Week 46 &Week 50）


③ 学术界 AI Memory 的关注同样在不断提升。以顶会的研究主题为


例，ICLR 2026 专门设立了「MemAgents」研讨会，旨在为智能体构


建一个能够支持单样本学习和长程一致性的底层记忆基底。[1-11]


3. 伴随学术界对 Memory 架构和机制的持续探索，以及 OpenClaw 在工


程上的「巨大成功」，长期以来被探讨的 AI 记忆问题开始形成边


界，并分化「LLM Memory」与「Agent Memory」两条演进路径。[1
4]


① LLM Memory 构成了预测的底层计算机制，存在两种具体形态：嵌


入在预训练模型权重中的参数化记忆，以及通过上下文窗口管理的运


行时记忆。LLM Memory 是基础的计算载体，其优先级在于在有限的


窗口内保证即时生成的准确性，而非维持连贯的自主行为。


② Agent Memory 则在前者的基础上延伸为系统性支撑自主行为的功


能流程。它不再仅生成孤立的文本，而是协调感知、规划、行动的循


环过程，使系统能够拆解并执行复杂任务。


4. 在 Agent 领域，或应用相对垂直的「Vertical Agent」语境下，记忆


（Agent Memory）不再是科学难题，而是一个可以通过场景拆解、针


对性构建得到解决的工程问题。[1-2] [1-3]


① 通过将数据组织为过程性、陈述性、元认知等不同格式，Agent


Memory 让系统能够从历史经验中学习，这一层级通过实现反思和策


略优化，推动数据从静态记录向动态 「经验」 转变，使 Agent 能够


基于过往结果演化自身行为。[1-4]


5. 相对于 Agent Memory 的繁荣，LLM Memory）仍存在诸多挑战，如


「稳定性-塑性困境」（Stability-Plasticity Dilemma）。当尝试通过微


调将新信息注入参数时，模型往往会丢失旧的、同样重要的知识 。[1
4]


AI Memory 的研究视角在如何变化？


1. AI Memory 的核心价值不止于缓解大语言模型的上下文窗口有限、交


互无状态等技术瓶颈，更被视为一种变革性赋能工具，推动人工智能


系统从通用工具升级为具备自适应、协作能力的以人为中心的智能


体。[1-4]


2. 伴随对 AI Memory 的持续探索，研究者开始从多样的视角审视这一


AI 能力的基石，并对其理论依据，运作机理及边界深入探索与迭代。


① 2025 年 4 月，华为诺亚方舟实验室的「From Human Memory to


AI Memory」从人类认知科学中的记忆理论出发，为理解 LLM Agent


的记忆机制提供了一个类比框架。[1-5]


② 2025 年 12 月，哈工大、鹏城实验室和复旦等机构的「AI Meets


Brain」则将人脑记忆机制与 Agents Memory 统一审视，并对其存储结


构展开剖析。[1-6]


3. 2026 年初，北邮百家 MemoryOS 团队与华为的研究者发表了新的综


述「Survey on AI Memory」，整合认知心理学与神经科学模型，明确


了 AI 领域中 「Memory」 的概念边界。


① 该综述将「Memory」的概念边界分为三层，LLM Memory 主要强


调计算核心，提供预测引擎；Agent Memory 聚焦于功能流程，负责管


理面向任务的执行过程。


③ 在 LLM 与 Agent 之上，「AI Memory」是最宏观的认知概念，


涵盖了人工认知的生物学灵感与终身学习的终极目标，聚焦于终身演


化与经验积累，统领前两者。


4. 在明确 AI Memory 层级边界后，研究者进一步提出了 4W 记忆分类


体系，以 When（生命周期）、What（类型）、How（存储）、Which


（模态） 四个正交核心维度对 AI 记忆系统进行分类，每个维度对应


AI 记忆的一项基础特征，同时结合认知科学、计算机工程等领域理


论，对各维度下的细分类型展开了详细界定与阐释。


① When（生命周期维度）聚焦记忆的存在时间与存续时长，从瞬时到


跨会话持久存储，对应记忆在 AI 智能体系统中的时间跨度特征；


② What（类型维度）基于认知科学理论，按记忆捕获的信息类型 /


知识性质划分，反映记忆在智能体行为中的功能角色；


③ How（存储维度）探究记忆的表示形式与存储技术实现方式，区分


模型内部的隐式存储与外部的显式存储；


④ Which（模态维度）按记忆处理的信息格式 / 模态划分，分为单模


态与多模态，体现 AI 记忆对不同类型信息的处理能力。


5. 此外，北邮和华为的研究者梳理了单智能体-多智能体记忆架构以及记


忆评估方法，并拆解了当前 AI 记忆发展所存在的架构冲突、理论方


法缺口、安全与运维复杂性三大核心瓶颈。


① 「架构冲突与系统限制」涵盖 LLM 有限的上下文窗口与长时经验


海量积累的矛盾；参数化记忆更新的计算成本高、易发生灾难性遗忘


的问题；多模态记忆的异构信息融合与统一表征难题。


② 「理论与方法学缺口」强调当前对记忆的研究偏重时间维度，忽视


对象与存储形式维度，概念碎片化；评估体系缺乏高阶能力指标（如


泛化性、稳健性）；多智能体记忆共享缺乏成熟的信息分区、同步与


一致性理论。


③ 「安全风险与运营复杂性」涉及不同场景。单智能体场景中，用户


数据存储需平衡个性化与隐私保护，易存在敏感信息推理风险；多智


能体协作场景中，静态权限设计无法适配复杂环境，易引发效率瓶颈


与数据不一致。


表：AI 记忆的 4W 分类法与技术体系。[1-4]


近期工作在如何探索 LLM Memory 和 Agent Memory？


1. 伴随业界 AI Memory 的重视，以及对推动 LLM 向持续学习与自主


智能演进的目标，2026 年初，研究者对 LLM Memory 的探索聚焦模


型原生上下文与知识存储机制，Agent Memory 的相关工作则面向多轮


交互、长期个性化与多智能体协作中的记忆管理。


2. DeepSeek 与北大的研究者在年初发布了「Engram」工作，提出了


「条件记忆」（conditional memory）的稀疏性维度，以补充现有 MoE


模型的条件计算范式，以解决 Transformer 架构缺乏原生知识查找原


语、需通过低效计算模拟检索的问题。[1-7]


① 该工作设计了「Engram」可扩展查找模块，借鉴经典 N-gram 嵌


入思想，实现 O （1） 时间复杂度的知识查找，让模型能基于输入局


部模式快速调用静态知识，无需反复通过深层计算重建高频、模板化


信息。


② 经测试，在同等参数与 FLOPs 条件下，27B 规模的 Engram 模


型在知识类任务（MMLU+3.4. CMMLU+4.0）、通用推理（BBH+5.0、


ARC-Challenge+3.7）及代码数学领域（HumanEval+3.0、MATH+2.4）


均显著超越 MoE 模型；长上下文任务中，Multi-Query NIAH 准确率


从 84.2% 提升至 97.0%。


③ 机制分析表明，Engram 将浅层网络从静态重建任务中解放，让深


层专注复杂推理，等效增加模型有效深度，同时其确定性检索特性支


持存算解耦，记忆表可部署于 CPU/SSD，大幅降低 GPU 显存依赖。


3. 针对 LLM Memory 的能力评估问题，盛大集团陈天桥团队近期提出了


提出了用于评估 LLM 长期交互式记忆能力的「EverMemBench」基准


测试，以解决现有基准测试多聚焦二元、单主题对话，难以捕捉现实


场景复杂性的问题。[1-8]


① EverMemBench 将记忆能力分解为三个核心评估维度，分别是细粒


度回忆、记忆意识和用户画像理解。细粒度回忆侧重对具体事实的精


准提取；记忆意识用于测试模型能否识别历史信息与新场景的关联性


并合理运用；用户画像理解关注模型从长期对话中挖掘用户隐含习惯


和特质的能力


② 研究者基于 EverMemBench 评估了多种长上下文语言模型（包括


Gemini-3-Flash、GPT-4.1-mini、LLaMA-4-Scout 等）和记忆增强系统


（如 Zep、Mem0、EverMemOS 等）的性能，并指出当前 LLM 的记


忆缺陷。


③ 实验结果表明，多跳推理在多参与方场景下性能急剧下降，表现最


佳的 Gemini-3-Flash 准确率仅为 26.51%，核心原因是多参与方场景


下相关信息分散在不同发言者、群组和时间点；时序推理仍是未解决


的难题，现有模型难以处理信息的版本语义和演变逻辑，最优模型准


确率不足 50%。


④ 此外，研究发现记忆意识受限于检索质量，现有基于相似度的检索


方法无法弥合查询与隐含相关记忆间的语义鸿沟，导致记忆增强系统


性能显著低于全上下文模型。


4. Agent Memory 方面，广东智能科学与技术研究院、东京科技大学和香


港理工的研究者近期参考大脑认知机制设计了多智能体记忆框架


「BMAM」，通过模拟海马体 - 新皮层的双记忆系统，结合前额叶皮


层的任务协调逻辑，解决多 Agent 协作中的记忆管理、时序一致性与


长程推理问题。[1-9]


① BMAM 框架采用模块化设计，包含海马体启发的情景记忆模块、


新皮层启发的语义记忆模块，以及负责记忆整合与检索的协调模块，


实现工作记忆与长期记忆的分层管理、并行更新与精准检索。


② 该工作提出了 「灵魂侵蚀（soul erosion）」 诊断视角，其定义为


时间连贯性、语义一致性和身份保全三个维度的综合退化，将 Agent


记忆失效模式与架构设计关联。


③ BMAM 针对 「灵魂侵蚀」每种模式设计了专用解决方案，如通过


StoryArc 时间线索引解决时间侵蚀，借助海马体到颞叶的整合机制稳


定事实以应对语义侵蚀，利用杏仁核启发的显著性标记保护身份相关


信息，避免被临时上下文覆盖。


④ 经测试， BMAM 在 LoCoMo 基准上准确率达 78.45%，跨会话


任务集成准确率 52.6%，优于现有多 Agent 记忆系统。消融实验则证


实了海马体式情景记忆是核心性能驱动因素，移除后准确率下降


24.62%，其他子系统则针对特定失效模式提供补充支持。


5. 人民大学信息学院，MemTensor 和上海高级算法研究院等机构的研究


者在近期工作中探究了长期个性化对话系统中记忆噪声积累、人格不


一致、无限对话与有限上下文冲突的问题，提出「Inside Out 」框架，


以显式结构化的 PersonaTree 作为长期记忆核心，实现无界交互下的


用户个性化状态维护。 [1-10]


① 「Inside Out 」框架借鉴认知科学中记忆的功能分工特性，将记忆


分解为情景记忆、语义记忆、显著性感知和控制导向四大功能专用子


系统，而非单一无结构存储，各子系统在不同时间尺度上协同工作。


② 该工作基于生物心理社会模型构建分层记忆 schema，设计迭代式


树更新机制，同时训练轻量级 MemListener 模型，通过过程奖励强化


学习将非结构化对话流转化为 ADD、UPDATE、DELETE 等可执行树


操作，实现记忆的动态演化与精准维护。


③ 推理阶段采用自适应生成 pipeline，快速模式直接用 PersonaTree


保障低延迟响应，代理模式则在树结构约束下按需引入细节，平衡效


率与个性化深度。


④ 实验验证，PersonaTree 在抑制上下文噪声、保持人格一致性上全


面优于全文连接与现有个性化记忆系统，且小模型 MemListener 即可


实现与大模型相当的记忆操作性能，开创 「小模型维护记忆、大模型


负责生成」 的高效协同范式，为长期个性化对话 Agent 提供了结构


化、可解释的记忆解决方案。

## 参考链接


[1-1] https://github.com/openclaw/openclaw


[1-2] https://www.usaii.org/ai-insights/vertical-ai-agents-explained-mechanisms-use-cases

[and-adoption](https://www.usaii.org/ai-insights/vertical-ai-agents-explained-mechanisms-use-cases-and-adoption)


[1-3] https://www.aalpha.net/blog/vertical-vs-horizontal-ai-agents/


[1-4] https://baijia.online/homepage/survey/Survey%20on%20AI%20Memory.pdf


[1-5] https://arxiv.org/pdf/2504.15965


[1-6] https://arxiv.org/abs/2512.23343


[[1-7] https://arxiv.org/pdf/2601.07372](https://arxiv.org/pdf/2601.07372)


[1-8] https://arxiv.org/pdf/2602.01313


[1-9] https://arxiv.org/pdf/2601.20465


[1-10] https://arxiv.org/pdf/2601.05171


[1-11] https://iclr.cc/virtual/2026/workshop/10000792
