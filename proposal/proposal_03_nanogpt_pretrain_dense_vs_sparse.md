# Proposal 03: 基于 nanoGPT 的预训练对比（Dense vs 原生稀疏）

## 目标

在可控小规模环境中比较：

1. 从头预训练 dense nanoGPT
2. 从头预训练固定结构化稀疏 nanoGPT

并评估两者在后续持续微调中的遗忘差异，回答“预训练阶段原生稀疏是否带来持续学习先天优势”。

---

## 研究问题

1. 原生稀疏预训练能否提升持续学习稳定性？
2. 稀疏预训练的初始性能劣势是否会被长期学习收益抵消？
3. 后稀疏化（Proposal 02）与原生稀疏预训练谁更有价值？

---

## 假设

### H1
原生稀疏预训练模型在持续微调中的遗忘率低于同规模 dense。

### H2
存在稀疏度区间使“初始困惑度劣势 < 长期保持收益”。

### H3
原生稀疏预训练在长期轮次上优于后稀疏化版本（需与 Proposal 02 联合对照）。

---

## 实验设计

## 1. 预训练组

固定参数预算下构建：

- `PD`：dense nanoGPT 预训练模型
- `PS-2:4`：2:4 原生稀疏预训练模型
- `PS-B`：block-sparse 原生稀疏预训练模型（可选）

可选附加组：
- `PD->S`：将 `PD` 后稀疏化（与 Proposal 02 对齐）

## 2. 训练公平性

- 相同训练 token
- 相同优化器与学习率 schedule
- 同一 tokenizer 与语料切分
- 报告 same-shape 与 matched-FLOPs

## 3. 持续微调阶段

在同一域序列上做持续学习：
- 代码 -> 数学 -> 医疗 -> 法律 -> 对话

主阶段不叠加 replay/EWC，先看预训练拓扑效应。

---

## 指标

预训练阶段：
1. Perplexity
2. 收敛速度
3. 训练稳定性

持续学习阶段：
1. Forgetting
2. BWT/FWT
3. 平均保持率
4. 交叉点轮次

---

## 预期输出

1. “后稀疏化 vs 原生稀疏预训练”路线对照图
2. 稀疏度与长期收益关系曲线
3. 对大模型阶段的路线建议：
- 若原生稀疏显著更优，投入稀疏原生预训练路线
- 若差异不显著，优先后稀疏化与系统机制优化

---

## 风险与应对

### 风险1：nanoGPT 规模过小导致外推性弱
应对：结论定位为“机制趋势”，不直接宣称大模型等价。

### 风险2：稀疏实现不稳定
应对：先固定一种稳定结构（2:4）跑通全流程，再加第二结构。

### 风险3：预训练成本超过预期
应对：先做 token 缩放试验，确认趋势后再扩展规模。

---

## 与其他 proposal 的关系

1. Proposal 01 提供机制贡献分解。
2. Proposal 02 提供大模型实用验证。
3. Proposal 03 提供“原生稀疏预训练是否更优”的基础证据。

三者组合后可形成完整路线闭环：
- 机制因果 -> 工程可用 -> 架构演化。

